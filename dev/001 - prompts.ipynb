{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate prompts.\n",
    "\n",
    "Methods:\n",
    "- pairwise comparison via logits (original PairS method)\n",
    "- direct-scoring via logits\n",
    "- activation harvesting\n",
    "\n",
    "Models:\n",
    "- Mistral 7B v0.1 Instruct\n",
    "- Llama 2 7B Chat\n",
    "- Llama 3 8B Chat\n",
    "\n",
    "Datasets\n",
    "- SummEval\n",
    "- News Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../utils\")\n",
    "from constants import *\n",
    "from prompts import *\n",
    "from utils import get_comparisons\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "instruction_theirs = lambda inst, article, s1, s2, aspect: theirs_compare.format(\n",
    "    INSTRUCTION=inst,\n",
    "    ARTICLE=article,\n",
    "    SUMMARY1=s1,\n",
    "    SUMMARY2=s2,\n",
    "    ASPECT=aspect\n",
    ")\n",
    "answer_theirs = lambda _1, _2: \"Answer: \"\n",
    "\n",
    "instruction_mine = lambda _, article, s1, s2, aspect: mine_compare.format(\n",
    "    ARTICLE=article,\n",
    "    SUMMARY1=s1,\n",
    "    SUMMARY2=s2,\n",
    "    ASPECT=aspect\n",
    ")\n",
    "answer_mine = lambda aspect, choice: f\"Between Choice 1 and Choice 2, the more {aspect} summary is Choice {choice}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"summeval\", \"newsroom\"]    \n",
    "    for model in [\"mistral\", \"llama2\", \"llama3\"]:\n",
    "\n",
    "        path = f\"{gdrive_path}/data/{dataset}-processed.jsonl\"\n",
    "        summaries = pd.read_json(path, orient=\"records\", lines=True)\n",
    "\n",
    "        # pairwise comparisons\n",
    "        path = f\"{gdrive_path}/prompts/{model}/{dataset}\"\n",
    "        chat_template = chat_templates[model]\n",
    "        for i in range(2):\n",
    "            instruction = [instruction_theirs, instruction_mine][i]\n",
    "            answer = [answer_theirs, answer_mine][i]\n",
    "            name = [\"theirs\", \"mine\"][i]\n",
    "            filename = f\"{path}_{name}\"\n",
    "            args = [summaries, chat_template, instruction, answer]\n",
    "            if name == \"mine\":\n",
    "                for choice in [1, 2]:\n",
    "                    comparisons = get_comparisons(*args, choice)\n",
    "                    comparisons.to_json(f\"{filename}_{choice}.jsonl\", orient=\"records\", lines=True)\n",
    "            else:\n",
    "                comparisons = get_comparisons(*args)\n",
    "                comparisons.to_json(f\"{filename}.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "        # direct-scoring\n",
    "        for aspect in [\"coherence\", \"consistency\", \"fluency\", \"relevance\"]:\n",
    "            prompts = []\n",
    "            for _, row in summaries.iterrows():\n",
    "                prompt = theirs_score.format(\n",
    "                    INSTRUCTION=theirs_instructions[aspect],\n",
    "                    ARTICLE=row[\"article\"],\n",
    "                    SUMMARY=row[\"summary\"],\n",
    "                    ASPECT=aspect_noun2adj[aspect]\n",
    "                )\n",
    "                prompt = chat_templates[model].format(\n",
    "                    INSTRUCTION=prompt,\n",
    "                    ANSWER=\"Score: \"\n",
    "                )\n",
    "                prompts.append(prompt)\n",
    "            summaries[f\"prompt_{aspect}\"] = prompts\n",
    "        summaries.to_json(f\"{gdrive_path}/prompts/{model}/{dataset}_score.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "        clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
