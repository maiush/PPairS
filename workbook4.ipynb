{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys; sys.path.append(\"utils\")\n",
    "from constants import *\n",
    "from sort import mergesort\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import spearmanr as rho\n",
    "\n",
    "\n",
    "aspects = [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consistency</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summeval</th>\n",
       "      <td>0.157673</td>\n",
       "      <td>0.223520</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.274193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsroom</th>\n",
       "      <td>-0.230378</td>\n",
       "      <td>-0.061689</td>\n",
       "      <td>-0.057818</td>\n",
       "      <td>-0.099357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          consistency  coherence   fluency  relevance\n",
       "dataset                                              \n",
       "summeval     0.157673   0.223520  0.109863   0.274193\n",
       "newsroom    -0.230378  -0.061689 -0.057818  -0.099357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consistency</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summeval</th>\n",
       "      <td>0.333165</td>\n",
       "      <td>0.274857</td>\n",
       "      <td>0.195807</td>\n",
       "      <td>0.25485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsroom</th>\n",
       "      <td>0.371129</td>\n",
       "      <td>0.432168</td>\n",
       "      <td>0.399630</td>\n",
       "      <td>0.53462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          consistency  coherence   fluency  relevance\n",
       "dataset                                              \n",
       "summeval     0.333165   0.274857  0.195807    0.25485\n",
       "newsroom     0.371129   0.432168  0.399630    0.53462"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consistency</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summeval</th>\n",
       "      <td>0.376793</td>\n",
       "      <td>0.349067</td>\n",
       "      <td>0.275211</td>\n",
       "      <td>0.352783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsroom</th>\n",
       "      <td>0.500515</td>\n",
       "      <td>0.509311</td>\n",
       "      <td>0.504053</td>\n",
       "      <td>0.484515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          consistency  coherence   fluency  relevance\n",
       "dataset                                              \n",
       "summeval     0.376793   0.349067  0.275211   0.352783\n",
       "newsroom     0.500515   0.509311  0.504053   0.484515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loop through all models, both datasets, and all aspects\n",
    "for model in [\"mistral\", \"llama2\", \"llama3\"]:\n",
    "    results = pd.DataFrame(columns=[\"dataset\"]+aspects)\n",
    "    for dataset in [\"summeval\", \"newsroom\"]:\n",
    "        result_row = [dataset]\n",
    "        for aspect in aspects:\n",
    "            path = f\"{gdrive_path}/logits_short/{model}/{dataset}_{aspect}.jsonl\"\n",
    "            logits = pd.read_json(path, orient=\"records\", lines=True)\n",
    "            logits[\"summary_id\"] = logits[\"summary_id\"].apply(lambda x: tuple(x))\n",
    "\n",
    "            # calculate correlation for each article, average them at the end\n",
    "            rs = []\n",
    "            for article in logits[\"article_id\"].unique():\n",
    "                subset = logits.loc[logits[\"article_id\"] == article, [\"summary_id\", aspect, \"p_s1\", \"p_s2\"]].copy()\n",
    "                # here we check the ids of each summary for a given article\n",
    "                ids = list(set([x for pair in subset[\"summary_id\"] for x in pair]))\n",
    "\n",
    "                # get the actual scores corresponding to the above summary ids\n",
    "                scores = pd.read_json(f\"{gdrive_path}/data/{dataset}-processed.jsonl\", orient=\"records\", lines=True)\n",
    "                scores = scores.loc[scores[\"article_id\"] == article, [\"summary_id\", aspect]].set_index(\"summary_id\")\n",
    "                scores = scores.loc[ids, aspect].values\n",
    "\n",
    "                # P is a square matrix: P[i, j] is the probability P(i >- j)\n",
    "                # default to just 0.5\n",
    "                #\n",
    "                # P_human isn't used here, but it's calculated in case it's useful later\n",
    "                P_human = np.zeros((len(ids), len(ids))) + 0.5\n",
    "                P_model = np.zeros_like(P_human) + 0.5\n",
    "                # looping through every pair of ids and recording the comparisons\n",
    "                for id1 in ids:\n",
    "                    for id2 in ids:\n",
    "                        if id1 == id2: continue\n",
    "                        if (id1, id2) in subset[\"summary_id\"].tolist():\n",
    "                            row = subset.loc[subset[\"summary_id\"] == (id1, id2), :]\n",
    "                            # get the original scores from human experts\n",
    "                            s1, s2 = row[aspect].item()\n",
    "                            # get the probabilities recorded from colab/logits.ipynb\n",
    "                            ps1, ps2 = row[[\"p_s1\", \"p_s2\"]].values.flatten()\n",
    "\n",
    "                            if s1 > s2:\n",
    "                                P_human[ids.index(id1), ids.index(id2)] = 1\n",
    "                                P_human[ids.index(id2), ids.index(id1)] = 0\n",
    "                            elif s1 < s2:\n",
    "                                P_human[ids.index(id1), ids.index(id2)] = 0\n",
    "                                P_human[ids.index(id2), ids.index(id1)] = 1\n",
    "\n",
    "                            # here we get the actual probabilities on comparisons\n",
    "                            P_model[ids.index(id1), ids.index(id2)] = ps1\n",
    "                            P_model[ids.index(id2), ids.index(id1)] = ps2\n",
    "\n",
    "                        # to save time, we ignored order effects when extracting logits,\n",
    "                        # so we need to account for this\n",
    "                        else:\n",
    "                            row = subset.loc[subset[\"summary_id\"] == (id2, id1), :]\n",
    "                            s2, s1 = row[aspect].item()\n",
    "                            ps2, ps1 = row[[\"p_s1\", \"p_s2\"]].values.flatten()\n",
    "\n",
    "                            if s1 > s2:\n",
    "                                P_human[ids.index(id1), ids.index(id2)] = 1\n",
    "                                P_human[ids.index(id2), ids.index(id1)] = 0\n",
    "                            elif s1 < s2:\n",
    "                                P_human[ids.index(id1), ids.index(id2)] = 0\n",
    "                                P_human[ids.index(id2), ids.index(id1)] = 1\n",
    "\n",
    "                            P_model[ids.index(id1), ids.index(id2)] = ps1\n",
    "                            P_model[ids.index(id2), ids.index(id1)] = ps2\n",
    "\n",
    "                # calculate uncertainty matrix\n",
    "                U = np.zeros_like(P_model)\n",
    "                for i in range(len(U)):\n",
    "                    for j in range(len(U)):\n",
    "                        U[i, j] = -P_model[i, j]*np.log(P_model[i, j] + 1e-10) - P_model[j, i]*np.log(P_model[j, i] + 1e-10)\n",
    "                # rank through PairS\n",
    "                # NOTE: my implementation of PairS sorts in descending order (highest scoring to lowest scoring)\n",
    "                model_ranking = mergesort(\n",
    "                    ixs = np.arange(len(P_model)),\n",
    "                    P = P_model,\n",
    "                    beam = True,\n",
    "                    beam_size = 1000,\n",
    "                    Uh = 0.6,\n",
    "                    U = U\n",
    "                )\n",
    "\n",
    "                if len(set(scores)) == 1:\n",
    "                    r = 1\n",
    "                else:\n",
    "                    # original implementation calculated correlation with np.arange(len(scores))\n",
    "                    # this correlation should be >= \n",
    "                    r = rho(scores[model_ranking], np.sort(scores)[::-1])[0]\n",
    "                rs.append(r)\n",
    "            result_row.append(np.mean(rs))\n",
    "        results.loc[len(results)] = result_row\n",
    "    results.set_index(\"dataset\", inplace=True)\n",
    "    print(model)\n",
    "    display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
